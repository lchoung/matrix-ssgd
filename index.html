<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>GPU Based SSGD Matrix Factorization by lchoung</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">GPU Based SSGD Matrix Factorization</h1>
      <h2 class="project-tagline">GPU Based Large Scale Matrix Factorization with Stochastic Gradient Descent</h2>
      <a href="https://github.com/lchoung/matrix-ssgd" class="btn">View on GitHub</a>
      <a href="https://github.com/lchoung/matrix-ssgd/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/lchoung/matrix-ssgd/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="proposal" class="anchor" href="#proposal" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Proposal</h3>

<p>GPU Based Large Scale Matrix Factorization with Stochastic Gradient Descent</p>

<p>Lillian Choung (lchoung)</p>

<h3>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h3>

<p>I plan to implement a parallel and distributed version of Non-Negative Matrix Factorization using the Stratified Stochastic Gradient Descent algorithm configuration with CUDA.</p>

<h3>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h3>

<p>Matrix factorization has applications in document clustering, recommendations, and signal processing. The core idea involves breaking a matrix M down to latent factor matrices A and B such that AB approximates M as much as possible according to some loss function L (potentially with some regularization to avoid overfitting). </p>

<p>To find A and B, I will use the Stochastic Gradient Descent method. The following repeats until convergence:</p>

<p><code>For each matrix square in M:</code></p>

<p><code>--&gt; Calculate the loss of the square in AB, compared to M.</code></p>

<p><code>--&gt; Adjust the elements of A and B that contribute towards the square, opposite the direction of the gradient.</code></p>

<p>An alternative to pure SGD is Stratified Stochastic Gradient Descent, as proposed by <a href="http://people.mpi-inf.mpg.de/%7Ergemulla/publications/gemulla11dsgd.pdf">Gemulla et. al.</a>. We can block a matrix and perform operations on each block concurrently, by selecting blocks whose necessary adjustments in A and B will not coincide with each other. We will use CUDA to parallelize these operations on blocks. </p>

<h3>
<a id="challenge" class="anchor" href="#challenge" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Challenge</h3>

<p>The one main challenge I foresee in this project:</p>

<ol>
<li><p>Since matrices large enough to warrant GPU speedup may prove to be billions of rows long, they may not fit in memory of a single computer. I may have to investigate a method of speaking between several GPUs (i.e. MPI). </p></li>
<li><p>Following (1): I must synchronize the values of A and B at the end of each iteration if I move towards a distributed CUDA system. The benefit of staying on GPU is that it lacks the latency of copying memory back and forth. Therefore, I will need to be careful about communication overhead. </p></li>
</ol>

<h3>
<a id="resources" class="anchor" href="#resources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resources</h3>

<p><a href="http://people.mpi-inf.mpg.de/%7Ergemulla/publications/gemulla11dsgd.pdf">SSGD: Gemulla et. al.</a>
<a href="http://www.almaden.ibm.com/cs/people/peterh/dsgdTechRep.pdf">Article on SSGD</a></p>

<p><a href="http://www.cse.buffalo.edu/faculty/miller/Courses/CSE710/heavner.pdf">OpenMPI + CUDA example</a></p>

<p>I plan to run experiments upon the latedays cluster. </p>

<h3>
<a id="goals" class="anchor" href="#goals" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Goals</h3>

<ol>
<li><p>Implement parallelized SSGD on CUDA for one machine</p></li>
<li><p>Distribute on multiple machines with MPI</p></li>
<li><p>Compare performance on <a href="http://academictorrents.com/details/9b13183dc4d60676b773c9e2cd6de5e5542cee9a">Netflix set</a> with in-memory R and Hadoop implementations mentioned in Gemulla. (If time)</p></li>
</ol>

<h3>
<a id="timeline" class="anchor" href="#timeline" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Timeline</h3>

<pre><code>Week 1: Achieve familiarity with tools / Implement SSGD on CUDA (one machine)
Week 2: Implement SSGD on CUDA
Week 3: Distributed implementations with MPI
Week 4: Distributed implementation with MPI
Week 5: Tuning parameters/Testing + Final paper
</code></pre>


<h2> Checkpoint </h2>

Over the last two weeks, I've:
<li><p>Parsed the input file of (row, column, entry) tuples to be stored on CPU.</p></li>
<li><p>Written the kernel that indexes into a block-and-chunk sorted list of tuples, and updates parameters after calculating the gradient. </p></li>
<li><p>Written the iteration logic that chooses which blocks run on which worker. </p></li>

I also started using some Thrust library functions to preprocess the data (sorting and then collecting by worker ID key), which I hadn't planned on using while writing the proposal.

I am a bit behind the schedule proposed in Proposal, because I am having trouble finding a space-efficient and fast way to take my input of (row, column, entry) tuples of my input matrix and transform it into the sorted format that would allow a CUDA kernel to index into the sorted list and retrieve the right entries on each iteration. 
My previous attempt used an "array of structures" and I'm refactoring to make it a "structure of arrays" instead. I also in my planning assumed the existence of some sort of key-pair data type in CUDA, which doesn't exist so I have to figure out how to put it all into a 1D vector. This is one of the main concerns right now.

Because of this complication, I'm not sure whether it is realistic to be able to get a multi-machine version of this running. I can also try to optimise the one machine version of this code, by experimenting more with the data storage and the worker partitioning part of the code. 

This current version of my code assumes that all the data can fit on the GPU memory. 
In the next few weeks my priorities are:

<li><p> Rest of this week: Fix the data wrangling </p></li>
<li><p> Sunday-Wednesday: Find ways to save space on the GPU, or potentially copy data back and forth from the CPU? </p></li>
<li><p> Thursday-Sunday: Implementation with large dataset bigger than GPU memory. </p></li>
<li><p> Last week: Parameter tuning and testing! </p></li>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/lchoung/matrix-ssgd">GPU Based SSGD Matrix Factorization</a> is maintained by <a href="https://github.com/lchoung">lchoung</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
